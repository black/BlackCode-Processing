

#############################################################################
## Copyright (c) 1996, Carnegie Mellon University, Cambridge University,
## Ronald Rosenfeld and Philip Clarkson
#############################################################################
=============================================================================
===============  This file was produced by the CMU-Cambridge  ===============
===============     Statistical Language Modeling Toolkit     ===============
=============================================================================
This is a 1-gram language model, based on a vocabulary of 993 words,
  which begins "<s>", "</s>", "A"...
This is an OPEN-vocabulary model (type 1)
  (OOVs were mapped to UNK, which is treated as any other vocabulary word)
Good-Turing discounting was applied.
1-gram frequency of frequency : 994 
1-gram discounting ratios : 1.00 
This file is in the ARPA-standard format introduced by Doug Paul.

p(wd3|wd1,wd2)= if(trigram exists)           p_3(wd1,wd2,wd3)
                else if(bigram w1,w2 exists) bo_wt_2(w1,w2)*p(wd3|wd2)
                else                         p(wd3|w2)

p(wd2|wd1)= if(bigram exists) p_2(wd1,wd2)
            else              bo_wt_1(wd1)*p_1(wd2)

All probs and back-off weights (bo_wt) are given in log10 form.

Data formats:

Beginning of data mark: \data\
ngram 1=nr            # number of 1-grams

\1-grams:
p_1     wd_1 

end of data mark: \end\

\data\
ngram 1=13
ngram 2=2

\1-grams:
-98.9996 <s>	0.0000
-1.14612 </s>	0.0000
-1.14612 ONE	0.0000
-1.14612 TWO	0.0000
-1.14612 THREE	0.0000
-1.14612 FOUR	0.0000
-1.14612 FIVE	0.0000
-1.14612 SIX	0.0000
-1.14612 SEVEN	0.0000
-1.14612 EIGHT	0.0000
-1.14612 NINE	0.0000
-1.14612 OH	0.0000
-1.14612 ZERO	0.0000

\2-grams:
-0.9324 ONE ONE
-0.9324 TWO TWO
\end\
