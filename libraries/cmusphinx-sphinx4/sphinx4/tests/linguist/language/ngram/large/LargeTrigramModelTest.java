/*
 * Copyright 1999-2002 Carnegie Mellon University.  
 * Portions Copyright 2002 Sun Microsystems, Inc.  
 * Portions Copyright 2002 Mitsubishi Electric Research Laboratories.
 * All Rights Reserved.  Use is subject to license terms.
 * 
 * See the file "license.terms" for information on usage and
 * redistribution of this file, and for a DISCLAIMER OF ALL 
 * WARRANTIES.
 *
 */
package linguist.language.ngram.large;

import edu.cmu.sphinx.linguist.WordSequence;
import edu.cmu.sphinx.linguist.dictionary.FastDictionary;
import edu.cmu.sphinx.linguist.dictionary.Word;
import edu.cmu.sphinx.linguist.language.ngram.large.LargeTrigramModel;
import edu.cmu.sphinx.util.Timer;
import edu.cmu.sphinx.util.TimerPool;
import edu.cmu.sphinx.util.Utilities;
import edu.cmu.sphinx.util.props.ConfigurationManager;

import java.io.*;
import java.util.*;

/**
 * Reads a binary language model file generated by the 
 * CMU-Cambridge Statistical Language Modelling Toolkit.
 * 
 * Note that all probabilites in the grammar are stored in LogMath log
 * base format. Language Probabilties in the language model file are
 * stored in log 10  base. They are converted to the LogMath logbase.
 */
public class LargeTrigramModelTest {

    public static void main(String[] args) throws Exception {

        String configPath;
        String testFile = null;
        PrintStream outStream = System.out;

        if (args.length == 0) {
            System.out.println
                ("Usage: java LargeTrigramModelTest <config_file> " +
                 "[<testFile>] " +
                 "<output_file>");
        }
        
        configPath = args[0];
        if (args.length >= 2) {
            testFile = args[1];
        }
        if (args.length >= 3) {
            outStream = new PrintStream(new FileOutputStream(args[2]));
        }

        ConfigurationManager cm = new ConfigurationManager (configPath);

        FastDictionary dictionary = (FastDictionary) cm.lookup("dictionary");
        LargeTrigramModel lm = (LargeTrigramModel) cm.lookup("trigramModel");

        InputStream stream = new FileInputStream(testFile);

        BufferedReader reader = new BufferedReader
            (new InputStreamReader(stream));

        Timer timer = TimerPool.getTimer(new Object(), "lmLookup");
        
        String input;
        
        List<WordSequence> wordSequences = new LinkedList<WordSequence>();
        
        while ((input = reader.readLine()) != null) {

	    if (!input.equals("<START_UTT>") && !input.equals("<END_UTT>")) {
		StringTokenizer st = new StringTokenizer(input);
		List<Word> list = new ArrayList<Word>();
		while (st.hasMoreTokens()) {
		    String tok = st.nextToken().toLowerCase().trim();
		    list.add(dictionary.getWord(tok));
		}
		WordSequence wordSequence = new WordSequence(list);
		wordSequences.add(wordSequence);
	    }	    
        }

        int[] logScores = new int[wordSequences.size()];
        int s = 0;

        timer.start();

        for (WordSequence ws : wordSequences) {
            lm.start();
            logScores[s++] = (int)lm.getProbability(ws);
            lm.stop();
        }

        timer.stop();
        
        s = 0;
        for (WordSequence ws : wordSequences) {
            outStream.println(Utilities.pad(logScores[s++], 10) + ' ' +
                getString(ws));
        }
        
        if (true) {
            long usedMemory = Runtime.getRuntime().totalMemory() - 
                Runtime.getRuntime().freeMemory();                
            System.out.println("Used memory: " + usedMemory + " bytes");
            System.out.println("NGram misses: " + lm.getNGramMisses());
        }
        
        
        TimerPool.dumpAll();
    }

    public static String getString(WordSequence ws) {
        StringBuilder line = new StringBuilder();
        for (int i = 0; i < ws.size(); i++)
            line.append(ws.getWord(i).getSpelling()).append(' ');
        line.setLength(line.length() - 1);
        return line.toString().toUpperCase();
    }
}

